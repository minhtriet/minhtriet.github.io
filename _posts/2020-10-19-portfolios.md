---
tags: knowledge-graph
comments: false
title:  Some of my works
excerpt: An overview and reflection of my portfolio
---
### Health hackathon
In 49 hours, create an health care app. ([Facebook](https://www.facebook.com/jvhackingfest/?fref=nf)) ([Featured in Tech in Asia](https://www.techinasia.com/jv-hacking-fest-healthcare-hackathon-vietnam))

**What I like:** Cool mentors. A dude gamified a hydration reminder. I teamed up with some random dudes right on the day of the hackathon, our ragtag team won 2nd price.

<figure>
<img src="https://cdn.techinasia.com/wp-content/uploads/2013/11/jv-hacking-fest-vietnam-saigon-720x540.jpg" alt="drawing" width="400"/>
<figcaption>I am the first from the right, top line</figcaption>
 </figure>
 
<iframe width="400" src="https://www.youtube-nocookie.com/embed/2OjyYhaLu5w?start=23" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

### Bachelor thesis
Use Machine Learning to fix [shibboleth for Vietnamese language speakers](https://en.wikipedia.org/wiki/Vietnamese_phonology#Initial_consonants)

**What I like:** Big impact, as 22.27% teachers and students of the capital city ([Source in Vietnamese](https://kenhtuyensinh.vn/gan-47000-giao-vien-va-hoc-sinh-noi-ngong)), our supervisor included, suffers from shibboleth. I lead in the team, and this project introduced me to machine learning and tried my hand at data collection and model deployment.

### Industrial robotics software
Pose estimation on a table top environment, with whole dataset consist of two images. My work is in University of Bonn's [EuroC Challenge](https://web.archive.org/web/20191204203324/http://www.euroc-project.eu/index.php?id=nimbro_manufacturing), [Paper](\href{https://arxiv.org/abs/2001.04134)

**What I like:** How to adapt when our training data consists of RGBD data of one images, and still deliver (A company named igus GmbH bought our work!)

### Master thesis
Gas price prediction

**What I like:** I step away from accepting the model as the black box and try to wrestle some sense out of it, which I found most papers that I've read lagging behind. Finally get to [publish it](http://ceur-ws.org/Vol-2611/paper2.pdf). Top ten most influential words to gas price according to my model. It is the table 6 in my work.

 
| 2012   | 2018 |
|--------|------|
| oil    | energy     |
| energy | gas      |
| price  | oil     |
| FTSE   | China     |
| fall   | Trump     |
| shale  | trade |
| power | price |
| coal | LNG |
| deal | UK |
| Shell | rise |

### Named Entity Recognition and Disambiguation (NERD) with Wikidata
Is it possible to do NERD in short queries, where there is fewer grammar clues or captitalization like in a sentence? 
Would the first and second Harry Potter `watch [harry potter] vs read [harry potter]` be resolved to `film` and `book`?
I create a demo [here](http://54.91.75.203/).

**What I like:** Tried my hand with ReactJS. I divise tests to see if cosine distance of different Word Embeddings suit the short text nature
